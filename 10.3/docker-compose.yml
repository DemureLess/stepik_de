
x-airflow-common:
  &airflow-common
  image: ${AIRFLOW_IMAGE_NAME:-airflow-with-java}
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
  volumes:
    - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
    - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
    - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
    - /var/run/docker.sock:/var/run/docker.sock
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy
    pg_extra:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  pg_extra:
    image: postgres:13
    environment:
      POSTGRES_USER: extradb_user
      POSTGRES_PASSWORD: extradb_password
    volumes:
      - pg-extra-db-volume:/var/lib/postgresql/data
    ports:
      - "5433:5432"  # доступ извне через порт 5433
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "extradb_user"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  redis:
    image: redis:7.2-bookworm
    expose:
      - 6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s
    restart: always

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.airflow.rule=Host(`airflow.localhost`)"
      - "traefik.http.routers.airflow.entrypoints=web"
      - "traefik.http.services.airflow.loadbalancer.server.port=8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    healthcheck:
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    environment:
      <<: *airflow-common-env
      DUMB_INIT_SETSID: "0"
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
      - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        if [[ -z "${AIRFLOW_UID}" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m"
          echo "If you are on Linux, you SHOULD follow the instructions below to set "
          echo "AIRFLOW_UID environment variable, otherwise files will be owned by root."
          echo
        fi
        mkdir -p /sources/logs /sources/dags /sources/plugins
        chown -R "${AIRFLOW_UID}:0" /sources/{logs,dags,plugins}
        /entrypoint airflow version
        # Create Airflow connections
        airflow connections add 'spark_default' \
          --conn-type 'spark' \
          --conn-host 'spark://spark' \
          --conn-port '7077' || true
        airflow connections add 'clickhouse_default' \
          --conn-type 'clickhouse' \
          --conn-host 'clickhouse' \
          --conn-port '9000' \
          --conn-schema 'default' \
          --conn-login 'user' \
          --conn-password 'strongpassword' || true
        airflow connections add 's3_default' \
          --conn-type 'aws' \
          --conn-login 'minioadmin' \
          --conn-password 'minioadmin123' \
          --conn-extra '{"endpoint_url":"http://minio:9000","region_name":"us-east-1"}' || true
        airflow connections add 'mongodb_default' \
          --conn-type 'mongo' \
          --conn-host 'mongo' \
          --conn-port '27017' \
          --conn-schema 'retail_data' \
          --conn-login 'admin' \
          --conn-password 'password123' \
          --conn-extra '{"authSource":"admin"}' || true
        airflow connections add 'kafka_default' \
          --conn-type 'generic' \
          --conn-host 'kafka' \
          --conn-port '29092' \
          --conn-extra '{"bootstrap.servers":"kafka:29092"}' || true
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      _PIP_ADDITIONAL_REQUIREMENTS: ''
    user: "0:0"
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}:/sources


  # Traefik - обратный прокси
  traefik:
    image: traefik:v2.10
    container_name: traefik
    restart: unless-stopped
    command:
      - --api.dashboard=true
      - --api.insecure=true
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --providers.docker.watch=true
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --log.level=DEBUG
    ports:
      - "80:80"
      - "443:443"
      - "8082:8080"  # Traefik Dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - default
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
  mongo:
    image: mongo:6.0
    container_name: mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password123
      MONGO_INITDB_DATABASE: retail_data
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.mongo.rule=Host(`mongo.localhost`)"
      - "traefik.http.routers.mongo.entrypoints=web"
      - "traefik.http.services.mongo.loadbalancer.server.port=27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - default
    restart: unless-stopped
    command: mongod --auth --bind_ip_all
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.3.3
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_HOSTNAME: kafka
      KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"
    container_name: kafka-server
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:29092 --list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8083:8080"  # Временно для отладки
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.kafka.rule=Host(`kafka.localhost`)"
      - "traefik.http.routers.kafka.entrypoints=web"
      - "traefik.http.services.kafka.loadbalancer.server.port=8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: true

      KAFKA_CLUSTERS_0_NAME: "Local Kafka Cluster - STEPIK_DE"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

      KAFKA_CLUSTERS_0_METRICS_CONFIG_TYPE: JMX
      KAFKA_CLUSTERS_0_METRICS_CONFIG_PORT: 9997
      KAFKA_CLUSTERS_0_METRICS_CONFIG_HOST: kafka

    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse-server
    restart: always
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.clickhouse.rule=Host(`clickhouse.localhost`)"
      - "traefik.http.routers.clickhouse.entrypoints=web"
      - "traefik.http.services.clickhouse.loadbalancer.server.port=8123"
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    environment:
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-user}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-strongpassword}
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  minio:
    image: minio/minio:latest
    container_name: minio-server
    restart: always
    ports:
      - "9002:9000"     # MinIO API
      - "9003:9001"     # MinIO Console
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=airflow_network"
      - "traefik.http.routers.minio.service=minio"
      - "traefik.http.routers.minio.rule=Host(`minio.localhost`)"
      - "traefik.http.routers.minio.entrypoints=web"
      - "traefik.http.services.minio.loadbalancer.server.port=9000"
      - "traefik.http.routers.minio-console.service=minio-console"
      - "traefik.http.routers.minio-console.rule=Host(`minio-console.localhost`)"
      - "traefik.http.routers.minio-console.entrypoints=web"
      - "traefik.http.services.minio-console.loadbalancer.server.port=9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin123}
      # Do NOT use MINIO_DOMAIN or MINIO_SERVER_URL with Traefik.
      # All Routing is done by Traefik, just tell minio where to redirect to.
      MINIO_BROWSER_REDIRECT_URL: "http://minio-console.localhost"
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    networks:
      - default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  spark:
    image: bitnamilegacy/spark:3.4.2
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.spark.rule=Host(`spark.localhost`)"
      - "traefik.http.routers.spark.entrypoints=web"
      - "traefik.http.services.spark.loadbalancer.server.port=8080"
    volumes:
      - ./data/spark:/opt/bitnami/spark/logs
    restart: unless-stopped

  spark-worker-1:
    image: bitnamilegacy/spark:3.4.2
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark:7077"]
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
    depends_on:
      - spark
    volumes:
      - ./data/spark-worker-1:/opt/bitnami/spark/logs
    restart: unless-stopped

  spark-worker-2:
    image: bitnamilegacy/spark:3.4.2
    command: ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark:7077"]
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
    depends_on:
      - spark
    volumes:
      - ./data/spark-worker-2:/opt/bitnami/spark/logs
    restart: unless-stopped

  jupyter:
    build:
      context: .
      dockerfile: infra/jupyter/Dockerfile
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.jupyter.rule=Host(`jupyter.localhost`)"
      - "traefik.http.routers.jupyter.entrypoints=web"
      - "traefik.http.services.jupyter.loadbalancer.server.port=8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=
      - JUPYTER_PASSWORD=
      - JUPYTER_ALLOW_ORIGIN=*
      - JUPYTER_ALLOW_REMOTE_ACCESS=true
      - JUPYTER_NO_PASSWORD=yes
    command: start.sh jupyter lab --LabApp.token='' --LabApp.password=''
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./data/spark:/opt/spark/logs
    restart: unless-stopped
    depends_on:
      - spark

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: always
    ports:
      - "3000:3000" 
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.localhost`)"
      - "traefik.http.routers.grafana.entrypoints=web"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin123}
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource
      GF_ALERTING_PROVISIONING_ALLOWED_EDITING: "true"
      GF_UNIFIED_ALERTING_ALLOWED_EDITING: "true"
      # Отключаем аутентификацию
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Admin"
      GF_AUTH_DISABLE_LOGIN_FORM: "true"
      GF_AUTH_ANONYMOUS_HIDE_VERSION: "true"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    depends_on:
      clickhouse:
        condition: service_healthy

  # Статический веб-сервер для главной страницы
  dashboard:
    build:
      context: .
      dockerfile: infra/start_panel/Dockerfile
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.dashboard.rule=Host(`localhost`)"
      - "traefik.http.routers.dashboard.entrypoints=web"
      - "traefik.http.services.dashboard.loadbalancer.server.port=8000"
    restart: unless-stopped
    networks:
      - default

networks:
  default:
    name: airflow_network

volumes:
  postgres-db-volume:
  pg-extra-db-volume:
  clickhouse_data:
  mongodb_data:
  minio_data:
  grafana_data:
