В базе данных PostgreSQL хранится таблица user_logins. В ней содержатся события пользователей, такие как логин, регистрация, покупка и т.д. Каждый раз, когда необходимо перенести эти события из PostgreSQL в другую систему (например, ClickHouse), можно воспользоваться Kafka как промежуточным звеном для передачи сообщений. 


Однако, в реальных задачах возникает риск повторной отправки уже обработанных данных. Чтобы избежать дублирования, нужно использовать дополнительное логическое поле в таблице — sent_to_kafka BOOLEAN, которое будет сигнализировать, были ли данные уже отправлены в Kafka.

Задание проверяется по следующим критериям:

- Работает продюсер: он не отправляет повторно записи и корректно выставляет флаг sent_to_kafka

- Работает консьюмер: получает данные из Kafka и сохраняет в ClickHouse

- README содержит описание пайплайна и как его запустить

В результате реализации получится устойчивое решение миграции данных с защитой от дубликатов.