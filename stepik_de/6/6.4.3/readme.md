## Установка и настройка

### 1. Установка зависимостей

```bash
pip install -r requirements.txt
```

### 2. Настройка переменных окружения

Скопируйте `.env.example` в `.env` и заполните ваши данные:

```bash
cp .env.example .env
```

Отредактируйте `.env` файл:

```bash
AWS_ACCESS_KEY_ID=your_actual_access_key
AWS_SECRET_ACCESS_KEY=your_actual_secret_key
AWS_ENDPOINT=https://s3.amazonaws.com
AWS_BUCKET=your_actual_bucket_name
```

### 3. Создание необходимых папок

```bash
mkdir -p in temp archive logs in
```

## Запуск

```bash
python result.py
```

Пайплайн начнет отслеживать папку `in/` и автоматически обрабатывать новые CSV файлы.

## Как это работает

1. **Мониторинг**: Пайплайн запускается и начинает отслеживать папку `in/`
2. **Обнаружение**: При появлении нового CSV файла автоматически запускается обработка
3. **Чтение**: CSV файл читается с помощью pandas
4. **Фильтрация**: Удаляются строки с пустыми значениями
5. **Сохранение**: Обработанные данные сохраняются во временный файл
6. **Загрузка**: Файл асинхронно загружается в S3
7. **Архивирование**: Исходный файл перемещается в папку `archive/`
8. **Очистка**: Временные файлы удаляются
9. **Логирование**: Все действия записываются в лог и загружаются в S3

## Логирование

Пайплайн ведет подробные логи всех операций:

- Запуск и остановка
- Обнаружение новых файлов
- Процесс обработки
- Загрузка в S3
- Перемещение файлов
- Ошибки и предупреждения

Логи сохраняются в:
- Файл `logs/pipeline.log`
- Консоль (для отладки)
- S3 хранилище (для анализа)

## Требования

- Python 3.8+
- Доступ к S3-совместимому хранилищу
- Установленные зависимости из `requirements.txt`



## Мониторинг и отладка

Для мониторинга работы пайплайна:

1. Проверьте файл `logs/pipeline.log`
2. Следите за выводом в консоли
3. Проверьте папку `archive/` на наличие обработанных файлов
4. Убедитесь, что файлы загружаются в S3

## Примеры использования

### Обработка одного файла
1. Поместите CSV файл в папку `in/`
2. Пайплайн автоматически обнаружит и обработает его
3. Проверьте результат в S3 и папке `archive/`

### Пакетная обработка
1. Поместите несколько CSV файлов в папку `in/`
2. Пайплайн обработает их последовательно
3. Все файлы будут загружены в S3 и перемещены в архив локально


### Демонстрация

#### Запуск и генерация файлов
![](https://github.com/DemureLess/stepik_de/blob/main/6/6.4.3/img/i_6_4_3_1.png)


#### Смотрим файлы в хранилище
![](https://github.com/DemureLess/stepik_de/blob/main/6/6.4.3/img/i_6_4_3_2.png)

#### Смотрим логи в хранилище
![](https://github.com/DemureLess/stepik_de/blob/main/6/6.4.3/img/i_6_4_3_3.png)
